\documentclass[sigplan,10pt]{acmart}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

\usepackage{acronym} % \ac[p], \acl[p], \acs[p], \acf[p]
\usepackage{algorithm} % \begin{algorithm} \end{algorithm}
\usepackage{algpseudocode} % \begin{algorithmic} \end{algorithmic}
\usepackage[inline]{enumitem} % \begin{enumerate*} \end{enumerate*}

\usepackage{graphicx}
\usepackage{color}
\AtBeginDocument{
\definecolor{pdfurlcolor}{rgb}{0,0,0}
\definecolor{pdfcitecolor}{rgb}{0,0,0}
\definecolor{pdflinkcolor}{rgb}{0,0,0}
\definecolor{light}{gray}{.85}
\definecolor{vlight}{gray}{.95}
\definecolor{darkgreen}{rgb}{0.0, 0.2, 0.13}
}

\usepackage[draft,inline,nomargin,index]{fixme}
\fxsetup{theme=colorsig,mode=multiuser,inlineface=\itshape,envface=\itshape}
\FXRegisterAuthor{go}{ago}{Gerald}
\FXRegisterAuthor{mn}{amn}{Matthieu}

\usepackage{subcaption} % subfigure

\def\algorithmautorefname{Algorithm}

% Commands
%---------
\newcommand{\ie}{i.e. }

\newcommand{\inbb}[1]{\in \mathbb{#1}}
\newcommand{\mathlist}[2]{\set{#1_i \in #2}_{i \inbb{N}}}
\newcommand{\set}[1]{\left\{#1\right\}} % set brace notation

% Acronyms
% --------
\acrodef{ADT}[ADT]{Abstract Data Type}
\acrodefplural{ADT}[ADTs]{Abstract Data Types}

\acrodef{CRDT}[CRDT]{Conflict-free Replicated Data Type}
\acrodefplural{CRDT}[CRDTs]{Conflict-free Replicated Data Types}

\acrodef{JIT}[JIT]{Just-In-Time}

\acrodef{OT}[OT]{Operational Transform}

\acrodef{P2P}[P2P]{Peer-to-Peer}

\acrodef{SEC}[SEC]{Strong Eventual Consistency}

\begin{document}

\title{Efficient Renaming in \acp{CRDT}}

\author{Matthieu Nicolas}
\email{matthieu.nicolas@loria.fr}
\affiliation{%
  \institution{Université de Lorraine, CNRS, Inria, LORIA, F-54500}
  \city{Nancy}
  \country{France}
}

\author{Gérald Oster}
\email{gerald.oster@loria.fr}
\affiliation{%
  \institution{Université de Lorraine, CNRS, Inria, LORIA, F-54500}
  \city{Nancy}
  \country{France}
}

\author{Olivier Perrin}
\email{olivier.perrin@loria.fr}
\affiliation{%
  \institution{Université de Lorraine, CNRS, Inria, LORIA, F-54500}
  \city{Nancy}
  \country{France}
}

\begin{abstract}
To achieve high availability, large-scale distributed systems have to replicate data and to minimise coordination between nodes. The literature and industry increasingly adopt Conflict-free Replicated Data Types (CRDTs) to design such systems. CRDTs are data types which behave as traditional ones, e.g. the Set or the Sequence. However, compared to traditional data types, they are designed to support natively concurrent modifications. To this end, they embed in their specification a conflict-resolution mechanism.

To resolve conflicts in a deterministic manner, CRDTs usually attach identifiers to elements stored in the data structure. Identifiers have to comply with several constraints such as uniqueness or being densely ordered according to the kind of CRDT. These constraints may prevent the identifiers’ size from being bounded. As the number of the updates increases, the size of identifiers grows. This leads to performance issues, since the efficiency of the replicated data structure decreases over time.

To address this issue, we propose a new CRDT for Sequence which embeds a renaming mechanism. It enables nodes to reassign shorter identifiers to elements in an uncoordinated manner. Obtained experiment results demonstrate that this mechanism decreases the overhead of the replicated data structure and eventually limits it.
\end{abstract}

\keywords{CRDT, real-time collaborative editing, eventual consistency, memory-wise optimisation}

\maketitle

\section{Introduction}

\begin{itemize}
    \item Real-time collaborative text editing
    \item \ac{OT}
    \item \ac{CRDT}
\end{itemize}

\section{Background}

To solve conflicts deterministically and ensure the convergence of all nodes, \acp{CRDT} relies on additional metadata.
In the context of Sequence \acp{CRDT}, two different approaches were proposed, each trying to minimise the overhead introduced.
The first one affixes constant-sized identifiers to each value in the sequence and uses them to represent the sequence as a linked list.
The downside of this approach is an evergrowing overhead, as it needs to keep removed values to deal with potential concurrent updates, effectively turning them into tombstones.
The second one avoids the need of tombstones by instead attaching densely-ordered identifiers to values.
It is then able to order values into the sequence by comparing their respective identifiers.
However this approach also suffers from an ever-increasing overhead, as the size of such densely-ordered identifiers is variable and grows over time.

In the context of this paper, we focus on the later approach.

\subsection{LogootSplit}

\begin{itemize}
    \item Attach dense identifiers to elements
    \item Group elements with adjacent identifiers into blocks to reduce overhead
\end{itemize}

\subsection{Limits}

\begin{itemize}
    \item Growth of identifiers
    \item Increasing number of blocks
\end{itemize}

\section{Proposed approach}

We propose a new Sequence \ac{CRDT} relying on dense identifiers to order elements : \emph{RenamableLogootSplit}.

To address the limitations of LogootSplit, we embed in this data structure a renaming mechanism.
The purpose of this mechanism is to reassign shorter identifiers to elements to reduce the metadata of the whole sequence.

\subsection{System Model}

The system is composed of a dynamic set of nodes, as nodes join and leave dynamically the collaboration during its lifetime.
Nodes collaborate to build and maintain a sequence using RenamableLogootSplit.
Each node owns a copy of the sequence and edit it without any kind of coordination with others.

Nodes communicate through a \ac{P2P} network, which is unreliable.
Messages can be lost, re-ordered or delivered multiple times.
The network is also vulnerable to partitions, which split nodes into disjoined subgroups.
To overcome the failures of the network, nodes rely on a message-passing layer.
As RenamableLogootSplit is built on top of LogootSplit, it shares the same requirements for the operation delivery.
This layer is thus used to deliver messages to the application exactly-once.
The layer also ensures that \emph{remove} operations are delivered after corresponding \emph{insert} operations.
Nodes use an anti-entropy mechanism to synchronise in a pairwise manner, by detecting and re-exchanging lost operations.

\subsection{\emph{rename} operation}

\emph{RenamableLogootSplit} enables nodes to reduce the overhead of their replica by the means of a new operation : the \emph{rename} operation.
This operation reassigns arbitrary identifiers to elements.

\begin{figure}
    \centering
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=1\textwidth]{img/renaming-first-id.png}
        \caption{Selecting the new identifier of the first element}
        \label{fig:renaming-first-id}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=1\textwidth]{img/renaming-second-id.png}
        \caption{Selecting the new identifier of the second one}
        \label{fig:renaming-second-id}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=1\textwidth]{img/renaming-final-state.png}
        \caption{Final state obtained}
        \label{fig:renaming-final-state}
    \end{subfigure}
    \caption{Renaming the sequence}
    \label{fig:renaming}
\end{figure}

Its behavior is illustrated in \autoref{fig:renaming} and can be described as follow :
\begin{enumerate*}
    \item It reuses the id of the first element of the sequence, but modified with the node's own id and sequence number (\autoref{fig:renaming-first-id})
    \item It generates contiguous identifiers for all following elements (\autoref{fig:renaming-second-id}).
\end{enumerate*}
As we assign contiguous identifiers to all elements of the sequence, we can eventually group them into one block as illustrated in \autoref{fig:renaming-final-state}.
It allows nodes to benefit the most from the block feature and to minimise the overhead of the resulting state.

In order for the system to eventually converge, other nodes have to rename their state identically.
To achieve this, the node issuing the \emph{rename} operation broadcasts its former state to others.
Using the former state, others compute the new identifier of each renamed identifier.
However, other nodes' states may contain concurrently inserted identifiers.
We will explain in \autoref{sec:dealing-with-concurrent-updates} how to rename them deterministically.

Broadcasting the \emph{rename} operation embedding the former state may be quite bandwidth consuming since the size of identifiers and the number of blocks are not bounded.
To partially adress this issue, we propose a compression mechanism which sends only the necessary components to identify uniquely a block instead of whole identifiers.
This compression mechanism allows to reduce to a fixed amount per block the metadata to broadcast.

As stated previously, nodes can issue operations without any coordination.
However, the designed \emph{rename} operation is not intrinsically commutative.
Additional steps are thus needed to handle scenarios with concurrent \emph{rename} operations.
For the sake of simplicity and brevity, we focus in this paper only on scenarios without any concurrent ones.
We leave the presentation and evaluation of mentioned additional steps to a future work.

\subsection{Dealing with concurrent updates}

\label{sec:dealing-with-concurrent-updates}

As \emph{rename} operations can be issued without any kind of coordination, it is possible for other nodes to perform updates concurrently.
Since identifiers are modified by the \emph{renaming} mechanism, applying concurrent updates as they are would result in inconsistencies as illustrated in \autoref{fig:concurrent-insert-rename-inconsistent}.
It is thus necessary to handle concurrent operations to \emph{rename} operations in a particular manner.

\begin{figure}
    \centering
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=1\textwidth]{img/concurrent-insert-rename-inconsistent.png}
        \caption{Concurrent update leading to inconsistency}
        \label{fig:concurrent-insert-rename-inconsistent}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=1\textwidth]{img/concurrent-insert-rename-fixed.png}
        \caption{Fixed scenario}
        \label{fig:concurrent-insert-rename-fixed}
    \end{subfigure}
    \caption{Dealing with concurrent updates}
    \label{fig:concurrent-insert-rename}
\end{figure}

To detect them, we use an \emph{epoch-based} system.
We add an \emph{epoch} to the sequence as a property.
Each time a \emph{rename} operation is applied, the sequence progresses to a new epoch.
When nodes issue operation, they tag them with their current epoch.
Upon the reception of an operation, nodes compare their current epoch to the operation's one.
If they differ, nodes have to transform the operation before applying it.

To transform an operation, nodes use the algorithm described in \autoref{alg:renamePos}.
This algorithm enables nodes to transform identifiers against the \emph{rename} operation.
The main idea of this algorithm is to use the predecessor of the given identifier to do so.
The algorithm consists mainly in
\begin{enumerate*}
    \item finding the predecessor of the given id in the former state
    \item computing its counterpart in the renamed state
    \item prepending it to the given id to generate the renamed id.
\end{enumerate*}
An example of its usage is illustrated in \autoref{fig:concurrent-insert-rename-fixed}.

Nodes applying remote \emph{rename} operations use the same algorithm to rename identifiers from their state which do not appear in the propagated state, \ie identifiers which has been inserted concurrently to the renaming.

Since nodes rely on the former state to transform concurrent operations to a \emph{rename} operation to preserve their semantics, nodes has to store it.
Nodes need it until each of them can not longer issue concurrent operations to the corresponding \emph{rename} operation.
In other words, nodes can safely garbage collect the former state once the \emph{rename} operation became causally stable.
Meanwhile, nodes can offload it onto the disk as it is only required to handle concurrent operations.

\begin{algorithm}
    \caption{Rename position}
    \label{alg:renamePos}
    \begin{algorithmic}
    \Function{renamePos}{$pos: P, newId: \mathbb{I}, newSeq: \mathbb{N}, renamedBlocks: \mathlist{b}{B}$}{: $P$}
        \State $firstPos \gets posBegin(renamedBlocks[0])$
        \State $lastPos \gets posEnd(renamedBlocks[renamedBlocks.length - 1]$\\

        \State $newPriority \gets priority(firstPos)$
        \State $newFirstPos \gets new \ P(newPriority, newId, newSeq, 0)$
        \State $newLastPos \gets new \ P(newPriority, newId, newSeq, length)$\\

        \If{$firstPos < pos$ \textbf{and} $pos < lastPos$}
            \State $predecessor \gets findPredecessor(pos, renamedBlocks)$
            \State $indexOfPredecessor \gets findIndex(predecessor, renamedBlocks)$
            \State $newPredecessor \gets new \ P(newPriority, newId, newSeq, indexOfPredecessor)$
            \State \Return $concat(newPredecessor, pos)$
        \ElsIf{$lastPos < pos$ \textbf{and} $pos < newLastPos$}
            \State \Return $concat(newLastPos, pos)$
        \ElsIf{$newFirstPos < pos$ \textbf{and} $pos < firstPos$}
            \State $predecessorOfNewFirstPos \gets new \ P(newPriority, newId, newSeq, -1)$
            \State \Return $concat(predecessorOfNewFirstPos, pos)$
        \Else
            \State \Return $pos$ \Comment Return the position unchanged as it does not interfere with the renaming
        \EndIf
    \EndFunction
    \end{algorithmic}
\end{algorithm}

\section{Evaluation}

\subsection{Simulations and benchmarks}

To validate the proposed renaming mechanism, we performed an experimental evaluation to measure its performances on several aspects:
\begin{enumerate*}
    \item the size of the data structure
    \item the integration time of \emph{insert} and \emph{remove} operations.
    \item the integration time of the \emph{rename} operation
\end{enumerate*} In cases 1 and 2, we use LogootSplit as the baseline data structure to compare results.

Since we were not able to retrieve an existing dataset of traces of realtime collaborative editing sessions, we ran simulations to generate traces to evaluate our data structure.
The simulations depict the following scenario: several authors collaborate in order to write an article.
Initially, they prioritise adding content as everything remains to be done.
Thus they mainly insert elements into the document during this first phase.
A few \emph{remove} operations are still issued to simulate spelling mistakes.
Once the document approaches the critical length, the collaborators switch to the second phase.
From this point, they stop adding new content and focus on revamping existing parts instead.
This is simulated by balancing the ratio between \emph{insert} and \emph{remove} operations.
Each author has to perform a given number of operations and the collaboration ends once every all of them received all operations.
We take snapshots of the document at given steps of the collaboration to follow the evolution of the document.

We ran these simulations with the following experimental settings : we deployed 10 bots as separate Docker containers on a single workstation.
Each container corresponds to a single mono-threaded Node.js process (version 13.1.0) simulating an author.
The bots share and edit collaboratively the document using either LogootSplit or RenamableLogootSplit according to the session.
In both cases, each bot performs an \emph{insert} or a \emph{remove} operation locally every 200 $\pm$ 50ms.
During the first phase, the probabilities for each operation of being an \emph{insert} or a \emph{remove} are respectively of 80\% and 20\%.
Once the document reaches 60k characters (around 15 pages), the probabilities are both set to 50\%.
The generated operation is then broadcast to others using a \ac{P2P} full mesh network.
After issuing an operation, there are 5\% of chances that the bot moves its cursor to another position in the document.
Each bot performs 15k operations.
Snapshots are taken every 10k operations overall.
Additionally, in the case of RenamableLogootSplit, one bot is arbitrarily designated as the master.
It performs \emph{rename} operations every 30k operations overall.

The code of the simulations is available at the following address: \url{https://github.com/coast-team/mute-bot-random/}.
This repository also contains the code corresponding to the benchmarks described in the next subsections as well as the results computed.

\begin{sloppypar}
Meanwhile, our implementation of LogootSplit and RenamableLogootSplit are available at \url{https://github.com/coast-team/mute-structs}.
Both implementations use an AVL Tree, a self-balancing binary search tree, to represent the sequence.
This data structure enables us to achieve \emph{insert} and \emph{remove} operations in logarithmic time.
\end{sloppypar}

\subsection{Results}

\paragraph{Memory overhead}

Using the snapshots generated, we compare the evolution of the size of the data structure in collaborative editing session.
The results are displayed in \autoref{fig:evolution-document-size}.
On this plot, the blue line corresponds to the size of the content while the red one exhibits the growth of the LogootSplit data structure.

\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{img/snapshots-sizes.pdf}
    \caption{Evolution of the size of the document}
    \label{fig:evolution-document-size}
\end{figure}

The green line illustrates the growth of the RenamableLogootSplit document in its best-case scenario.
In this scenario, \emph{rename} operations become stable as soon as they are issued.
Former states can then be garbage collected safely, maximising the benefits of the \emph{renaming} mechanism.
In this case, we observe that \emph{rename} operations reset the overhead of the data structure and eventually reduce by hundred times the document size compared to LogootSplit equivalent one.

As for the orange line, it represents RenamableLogootSplit worst-case scenario.
Here, we assume that \emph{rename} operations never become stable and that nodes has to store former states forever.
However, obtained results show that RenamableLogootSplit outperforms LogootSplit and reduce by 66\% the size of the data structure, even in this case.
This outcome is explained by the fact that the AVL does not only store the content and blocks corresponding to the sequence.
Some metadata is actually added to the state to browse the sequence more efficiently when performing updates.
When a \emph{rename} operation is applied, nodes only keep the sequence of blocks from the former state as an array to be able to transform concurrent operations.
Other metadata is scrapped, which results in this memory gain.

\paragraph{Integration times of standard operations}

We set up benchmarks to measure the impact of the renaming mechanism on the integration times of \emph{insert} and \emph{remove} operations.
The obtained results are presented in \autoref{fig:evolution-integration-time-insert-remove}.

\begin{figure}
    \centering
    \begin{subfigure}{0.35\textwidth}
        \includegraphics[width=1\textwidth]{img/integration-time-boxplot-local-operations-without-outliers.pdf}
        \caption{Local operations}
        \label{fig:evolution-integration-time-local-insert-remove}
    \end{subfigure}
    \begin{subfigure}{0.35\textwidth}
        \includegraphics[width=1\textwidth]{img/integration-time-boxplot-remote-operations-without-outliers.pdf}
        \caption{Remote operations}
        \label{fig:evolution-integration-time-remote-insert-remove}
    \end{subfigure}
    \caption{Evolution of the integration time of standard operations}
    \label{fig:evolution-integration-time-insert-remove}
\end{figure}

\autoref{fig:evolution-integration-time-local-insert-remove} displays the integration times of local operations while \autoref{fig:evolution-integration-time-remote-insert-remove} exhibits remote ones.
In both cases, the orange boxplots correspond to LogootSplit's integration times while blue ones to RenamableLogootSplit's ones.
The results show that the \emph{renaming} mechanism allows to reduce the integration times of future operations.

In \autoref{fig:evolution-integration-time-remote-insert-remove}, the green boxplots display the integration times of concurrent operations to a \emph{rename} one.
As illustrated in \autoref{sec:dealing-with-concurrent-updates}, these operations require to be transformed before being applied to the renamed state.
The results presented here show that this is actually faster than applying them directly on the former state.

\paragraph{Integration time of \emph{rename} operation}

Finally, we measured the integration time of the \emph{rename} operation according to the size of the document.
Results are displayed in \autoref{fig:evolution-integration-time-rename}.
In this figure, the blue line corresponds to the integration time of a \emph{local} rename operation while the orange one corresponds to the integration time of a remote one.

\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{img/integration-time-rename.pdf}
    \caption{Evolution of the integration time of rename operations}
    \label{fig:evolution-integration-time-rename}
\end{figure}

The main result of this benchmark is that the unit of time used when applying \emph{rename} operations is in hundreds of milliseconds.
However other operations can not be integrated during the processing of \emph{rename} operations : remote operations won't be displayed to the user while local ones won't be propagated to others.
\emph{Rename} operations can thus be perceived as spikes of latency by users and degrade their experience if they are too long to process.
It is necessary to take this concern into account when designing the strategy used to trigger \emph{rename} operations to avoid such cases.

\section{Related works}

\begin{itemize}
    \item Core and Nebula
    \item LSEQ
    \item Specification and Complexity of Collaborative Text Editing
    \item OT
\end{itemize}

\section{Conclusions and future work}

\begin{itemize}
    \item Designed new dense identifier-based Sequence CRDT embedding a renaming mechanism : \emph{RenamableLogootSplit}
    \item Achieved better performances memory-wise than state of the art, even in worst-case scenario...
    \item ... at the cost of expensive but infrequent \emph{rename} operations
    \item Study user behavior to set a limit to integration time of \emph{rename} operations
    \item Present and validate mechanism to handle concurrent \emph{rename} operations
    \item Design strategies to limit likelyhood of concurrent \emph{rename} operations
    \item Design strategies to limit overall workload in case of concurrent \emph{rename} operations
\end{itemize}

\end{document}
